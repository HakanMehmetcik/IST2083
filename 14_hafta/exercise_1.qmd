---
title: "Exercise 1"
author: "Hakan Mehmetcik"
format: pdf
editor: visual
execute: 
  echo: true
  warning: true
  output: asis
df-print: kable
---

```{r setup, echo=FALSE, message=FALSE}
# loaded packages
library(tidyverse)
library(here)
dpath <- "13_hafta_exercises"
```

# Exercise 1: Exploring the Data

## Reading the Data

Let’s first read in a dataset called simd2020.csv, which is the 2020 Scottish Index of Multiple Deprivation (SIMD) for all Scottish datazones.[^1]

[^1]: A datazone is a small geographical area, here of Scotland. The datazones in the SIMD are nested in council ar- eas, are roughly equal sized (500 to 1,000 people), and are constructed to maintain physical and natural communities (www.gov.scot/Topics/Statistics/SIMD/FAQUsingSIMD)

```{r}
#| warning: false
#| error: false
simd2020 <- read_csv(here(dpath, "simd2020.csv"), na="*")
```

::: callout-note
👋 In the read_csv() function, we include the name of the file ("simd2020.csv") and we also specify how the missing values are characterized in the .csv file. We will deal more explicitly with missing values later on, but for now we include the option na="*", where na means ‘not available’ and* is how missing values are represented in the raw SIMD data. This ensures that missing values from the .csv data file are coded in the way that R recognizes missing values (i.e., "NA").
:::

::: callout-note
⚠️ It is always a good practice if you read the data description (or the so-called code-book) first, before to work on any data!
:::

## Examining Dataset

There are a few different ways using base R and tidyverse to look at the dataset. The first option is to ‘view’ the dataset using the view() function from the tibble package. We put the name of the dataset object into the parentheses of view(). This opens up a new tab in RStudio where we can see all the variables and observations. The view() function is the lower-case version of the View() function in base R.

```{r}
view(simd2020)
```

Another way to take a quick look at the variables in our data is using the names() function. This function provides the names of all the variables in our dataset, and is particularly useful when performing analysis and we cannot remember the particular name of a certain variable.

```{r}
names(simd2020)
```

We can also look at the class of the dataset using the class() function. This is important as R functions require that data are specified as certain classes.

```{r}
class(simd2020)
```

::: callout-note
💡 This shows four different classes, where tbl stands for tibble. Note that the data is also classified as a data.frame which is the standard data frame class and would be the only class listed if we used read.csv(). Therefore, our dataset will work for tidyverse and non-tidyverse functions.
:::

## Examining Variables

Now that we have correctly read in and taken a quick look at our data, we want to examine the contents of our variables. There are a number of things we might want to look at in our variables, but we are usually most interested in the variable type. At the most basic level, we want to know whether our variables are numeric or string/character. Numeric variables are composed of numbers, while string or character variables are composed of letters or symbols. We likely already know whether our variables are numeric or string/character, but sometimes when we read data into R, variables will be misclassified. For example, numeric variables wind up mischaracterised as string/character variables. Since our data analysis is, usually, dependent on numbers, we will not be able to perform statistical analysis with string/character variables. That is why it is always good practice to make sure that our variables are the correct variable type from the start. The next thing we are concerned about are whether our numeric variables are being treated as numeric (the values imply some order), integer (numeric variables that only include integers), or whether they are treated as factor (variables whose numeric values do not have order). As with numeric and string/character variables, we probably know whether the variables should be numeric or factor. With factor variables, we are restricted from doing certain types of statistical analysis. Tidyverse follows base R in classifying variable types, but it uses slightly different terminology in places. When we read-in data using tidyverse() functions, the numeric variables are specified as col_double(), integer variables are specified as col_integer(), string/character variables are specified as col_character(), and factor variables are specified as col_factor(). The prefix col\_ simply refers to ‘column’, where ‘column’ is the generalized term for what we are calling ‘variables’. We can see the specifications (i.e., classifications) by using the spec() function from the readr package.

```{r}
spec(simd2020)
```

This shows we have 3 variables specified as character and the rest are classified as double. We actually saw a summary of this information when we used the read_csv() function, but here it is provided for each variable. To get a quick look at our variables, we can use the glimpse() function from the pillar package; pillar is not part of tidyverse, but tidyverse automatically imports pillar functions when loaded. The glimpse() function is the tibble-friendly version of the str() function.

```{r}
glimpse(simd2020)
```

The output provides a summary of the number of rows and columns (which is the same information as in the Environment window), the variable names, the classification type of each variable, and the first few values of each variable. This output is most useful for checking the variable classifications and whether any wonky values are present. For example, we see that a number of variables (e.g., ALCOHOL) have many numbers to the right of the decimal point. Depending on our analysis goals, we likely will want to round these variables to have only 2 or 3 decimal places. Also, notice that the specification types are abbreviations - here, we have <chr> for a character variable and <dbl> for a double variable. If we are only interested in a single variable’s classification, we can use the class() function. Unless we create a separate object for the variable, we need to tell R what dataset the variable belongs to. We do this by specifying the name of the dataset, then include a dollar sign (\$), followed by the name of the variable. Let’s look at the variable Council_area:

```{r}
class(simd2020$Council_area)
```

We see that the variable type is character for Council_area. We can do the same for any variable in our dataset. If we want to look at the first few rows of a variable, we can use the head() function.

```{r}
head(simd2020$Council_area)
```

This shows that the first few observations are “Aberdeen City”. If we want to look at the last few rows of a variable, we can use the tail() function.

```{r}
tail(simd2020$Council_area)
```

This shows that the last few observations are “West Lothian”.

We can also get basic statistical summaries of our variables by using the summary() function. Depending on the variable type, we will get different statistical summaries. First, let’s look at Total_population which is a double variable.

```{r}
summary(simd2020$Total_population)
```

This provides the minimum, maximum, median, mean, and first and third quartiles. Now, let’s look at Council_area, which is a character variable.

```{r}
summary(simd2020$Council_area)
```

Since Council_area is a character variable, R only gives us the total number of observations, the class, and a mode of character. For examining Council_area, this output is not useful.

Instead of using the summary() function, we can use two different options to see the values for character and factor variables. First, let’s use the table() function to see all the council areas and the number of observations.

```{r}
table(simd2020$Council_area)
```

This shows the number of observations for all 32 council areas. Second, let’s use the count() function from the dplyr package. The count() function literally counts the number of observations and is commonly used when we are grouping the data by multiple observations. To use count(), we need to introduce a new coding concept and syntax. Tidyverse utilizes pipes which allows us to link multiple functions together in one block of code. While this is a more elegant coding approach, it also makes tidyverse easier to work with and allows us to manipulate multiple aspects of the data simultaneously.

We start using pipes with the \|\> pipe operator. This is one of several pipe operators and is the most extensively used. We can think of \|\> as telling R to continue to and combine the next line of code with the previous line. Although though not strictly correct, I tend to think of \|\> as adding together lines of code. Let’s use the count() function to see the number of observations (which are datazones) per council area.

```{r}
simd2020 |> 
  count(Council_area)
```

The output shows the first 10 council areas alphabetically and that there are an additional 22 council areas not shown. Depending on our goal, this might not be very useful. Instead, we often want sort variables by the most or least number of observations. We can do this by adding the option sort=TRUE into the count() function specification.

```{r}
simd2020 |> 
  count(Council_area, sort = TRUE)
```

This shows that Glasgow City and City of Edinburgh have the most observations in the data; which makes sense since they are the two largest cities in Scotland.

## Managing the Missing Values

When reading in data and before we perform statistical analysis, we often need to deal with the missing values in some way. In the next classes, we will look at recoding variables, where we specify certain variable values as missing, but here we will look at dealing with missing values in the aggregate. While we could remove all observations with missing values for any variable in a dataset, this approach often removes more observations than is needed. An alternative approach is to remove observations with missing values only for the specific variables we are using. We can do this with the filter() function from the dplyr package. The filter() function acts just as you imagine - it filters the data based on a set of conditions. Below, we use the is.na() function in the filter() function to remove missing values from the variable Attendance. Since is.na() means ‘is missing’, we actually need to specify that we want to keep observations that are ‘not missing’. To do this, we include ! before is.na(); ! means ‘not’.

```{r}
simd2020 |> 
  filter(!is.na(Attendance))
```

The output shows there are 6409 datazones that do not have missing values for Attendance. For completeness, let’s see what happens when we do not include !.

```{r}
simd2020 |> 
  filter(is.na(Attendance))
```

This time the output shows there are 567 datazones that do have missing values for Attendance.

## Subsetting the Data

There are many reasons why we might want to subset data. Particularly when we download public data, we often want to get rid of irrelevant variables. Or, we may only want to work with a handful of variables instead of hundreds or thousands of variables. While we could use the common subset() function, subsetting in tidyverse is a terrific introduction to the data wrangling approach of tidyverse. We make use of the select() function from the dplyr package, where we specify the variables we want to subset. We will create a new object for each new tibble in order to take a closer look. First, we will subset the data to keep a single variable - Council_area.

```{r}
simd1 <- simd2020 |> 
  select(Council_area)
```

To select an additional variable, we just include a comma and then the variable name.

```{r}
simd2 <- simd2020 |> 
  select(Council_area, Total_population)
```

If we want to subset for a range of variables, we can include a colon.

```{r}
simd3 <- simd2020 |> 
  select(Council_area:Income_rate)
```

Often, especially when we are just exploring the data, we want to drill down to specific observations or variable values. We can do this by using the filter() function with the select() function. We will first subset the data to only look at datazones in Glasgow City. Note, we need to specify == and not = in the code. Also, if we are using the select() function, the variable we are filtering needs to be included in the selected variables.

```{r}
simd4 <- simd2020 |> 
  select(Intermediate_Zone:Income_rate) |> 
  filter(Council_area=="Glasgow City")
```

We see in the Environment window that there are 746 datazones in Glasgow City. We can drill further down by adding new conditions. Below we ask for the Hillhead intermediate zone of Glasgow City; we can think of an intermediate zone as a neighborhood. We do this by including & Intermediate_Zone=="Hillhead", where, as you might guess, & is for ‘and’. Our filter() function specification tells R to only keep observations that are in Glasgow City and are in the Hillhead intermediate zone.

```{r}
simd5 <- simd2020 |> 
  select(Intermediate_Zone:Income_rate) |> 
  filter(Council_area=="Glasgow City" & Intermediate_Zone=="Hillhead")
```

::: callout-note
👋 In this case, this latest subsets the data down to 7 datazones. (Although it might appear that specifying the Council_area is redundant, if we do not include it we will actually get datazones in a suburb of Glasgow.)
:::

Sometimes we want to subset data by a certain variable value. This might be a string (or character) or numeric value. First, let’s look at how to do this with a string/character value. Let’s subset the data to only include intermediate zones in cities’ downtowns - which is commonly referred to “city centre” in the UK. We will use the str_detect() function from the stringr package, wrapped by the filter() function, which literally detects the string value we specify; here, "Centre".

```{r}
simd6 <- simd2020 |> 
  select(Intermediate_Zone:Income_rate) |> 
  filter(str_detect(Intermediate_Zone, "Centre"))
```

Looking at simd6’s observations, we see this actually does a poor job - as a number of small town centres are included and Edinburgh is completely missing. Second, let’s subset the data by a specific numeric value. Here, we’ll do a simple version where we filter for datazones that have 25% or more of its residents classified as employment deprived (which includes the number of people receiving unemployment support, disability or incapacity support, etc.). We specify the variable (Employment_rate), the greater than or equals condition (\>=), and the numeric value (.25 for 25%).

```{r}
simd7 <- simd2020 |> 
    select(Intermediate_Zone:Income_rate, Employment_rate) %>%
    filter(Employment_rate >= .25)
```

We see this includes 293 datazones. Let’s further drill down to see how many of these datazones are in Glasgow by adding Council_area=="Glasgow City to the filter() function.

```{r}
simd8 <- simd2020 |> 
    select(Intermediate_Zone:Income_rate, Employment_rate) %>%
    filter(Employment_rate >= .25 & Council_area=="Glasgow City")
```

We see that Glasgow has 113 of the 293 datazones where 25% or more of its residents are employment deprived. (Glasgow is generally considered to be the most deprived city in the UK.)

## Merging Different Dataset

Tidyverse provides a number of ways to merge data through the use of join() functions from the dplyr package. The key, pun intended, of all the join() functions is that there needs to be a variable (a key) in each dataset we are merging that can individually identify the cases/observations. Without this key we are unable to merge the data. We specify the key using the by= option in the join() functions. We start by using the inner_join() function, which we use when the datasets all have the same number of observations; otherwise, all unmatched observations will be deleted. We are going to merge the 2020 SIMD data with a dataset that has the NHS Scotland health boards by datazone. We need to first read-in the health board data (titled scottish health boards by datazone.xlsx) using the read_xlsx() function.

```{r}
healthboard <- readxl::read_xlsx((here(dpath, "scottish health boards by datazone.xlsx")))
glimpse(healthboard)
```

We see there are the same number of observations as the 2020 SIMD data. Because the keys have different variable names, we need to specify the keys for each dataset. We specify the key (Data_Zone) from our first dataset (simd2020) first and then the key (data_zone) from the dataset we are merging (healthboard) second.

```{r}
merge_simd1 <- simd2020 |> 
  inner_join(healthboard, by=c("Data_Zone"="data_zone"))
glimpse(merge_simd1)
```

Viewing the merged data, we see that we have just pasted 3 variables from the health boards data (intermediate_zone, council_area, and health_board) to the end of the SIMD data. The data_zone variable is removed since we told R that it had the same information as Data_Zone. If we had identical variable names in the merged datasets, then additional information as suffixes are automatically added to the duplicate variable names; with just two datasets, .x and .y will automatically be added to the duplicate variable names. Even though the SIMD data already has variables for the intermediate zone and council area, the variable names are not identical (because of the use of upper- and lower-case letters) and thus suffixes are not added. If we know there are duplicate variables, we can remove them when we do the merge by adding the select() function and specifying which variables to remove by including -c(). Doing this clearly demonstrates the benefit of using tidyverse - we are able to merge and subset the data in a single code chunk. Below we repeat the merge and remove Rows: 6,976 Columns: 39 \$ Data_Zone \$ Intermediate_Zone \$ Council_area intermediate_zone and council_area that were in the healthboard data.

```{r}
merged_simd1 <- simd2020 |> 
      inner_join(healthboard, by=c("Data_Zone"="data_zone")) |> 
      select(-c(intermediate_zone, council_area))
glimpse(merged_simd1)
```

We now see that intermediate_zone and council_area have been removed. If we do not want to delete unmatched observations, there are several alternatives to the inner_join() function. Commonly, we want to preserve the observations in one main dataset when merging additional datasets. In this case, we can use the left_join() function, which keeps all the observations that appear in the first dataset (the left or X dataset) and deletes all the unmatched observations that appear in the second dataset (the right or Y dataset). Any observations in the first dataset that are not matched to the second dataset will have “NA” included for the variable values of the second dataset.

```{r}
merged_simd2 <- simd2020 |> 
      left_join(healthboard, by=c("Data_Zone"="data_zone")) |> 
      select(-c(intermediate_zone, council_area))
glimpse(merged_simd2)
```

In this case, the merged_simd2 dataset is the same as the merged_simd1 dataset because they have the same observations. Other join functions include the right_join(), full_join(), semi-join(), and anti_join() functions. The right_join() function keeps all the observations in the second dataset (the right or Y dataset), the full_join() function keeps all the observations from both datasets, the semi_join() function keeps all the observations in the first dataset with a match in the second dataset, and the anti_join() function keeps all the observations in the first dataset without a match in the second dataset. Lastly, the join() functions allows us to merge more than two datasets at the same time (i.e., 3, 4, etc.) as long as each dataset has a key to link the observations. The join() functions provide an easy and effective way to merge different datasets in R. However, it is very easy to use the wrong join() function for what we want to accomplish. Therefore, it is important to closely examine our merged data before moving onto any analysis.

## Pivoting the Dataset

We can perform an array of different data pivoting using the tidyr package. If you have done table pivoting in Excel, then you are already familiar with the concept of data pivoting. Pivoting simply involves simultaneously transforming columns to rows and row to columns. We commonly pivot data for specific types of data visualizations and statistical analysis techniques. Let’s read-in a new dataset on the number of COVID-19 cases by NHS Scotland health board to demonstrate data pivoting. The file is called covid total by health board.xlsx and we’ll use the read_xlsx() function.

```{r}
covid <-readxl::read_xlsx(here(dpath, "covid total by health board.xlsx"))
covid
```

This data is wide or what the tidyverse folks would call untidy data. To tidy the data, we are going to move each year’s covid total to a new row for health board. To do this, we will use the pivot_longer() function from the tidyr package, where we first specify the variables to pivot, then the name of a new variable with the original variable names (here, year), and finally the name of a new variable with the original variables’ values (here, cases).

```{r}
covid1 <- covid |> 
    pivot_longer(c(`2020`,`2021`), names_to="year",
                 values_to = "cases")
covid1
```

We see that the new dataset covid1 now has 28 observations (14 observations X 2 variables). This data is now considered tidied. We can do the reverse with the pivot_wider() function from the tidyr package.

```{r}
covid2 <- covid1 |> 
    pivot_wider(names_from="year", values_from="cases")
covid2
```

## Saving the Data

Now that we have done all this work of reading in data, dealing with missing values, and subsetting data, we probably want to save the work we have done. In truth, it is not critical to save everything we did, because by having a saved R script or R Markdown file of all the code we can easily recreate our work during a different R session. However, let’s consider several ways of saving our data. Saving data in R is slightly different from many statistical programs. Many programs like Stata allow you to simply save the data like you might in Word. In R, we generally use a write() function where we ‘write’ our data in a specific format, which creates a new data file that we save (usually in our working directory). As we saw with reading in different types of data formats, we can write to different types of data formats. We should also make sure that the data is correctly saved in the file type. For example, .csv files can struggle with text characters and, possibly obviously, commas in the data. If this occurs, we might want to save the data as a .xlsx file. Saving data to proprietary statistical program file types like Stata also can cause problems. For example, Stata does not allow certain characters to be used in variable names and thus may refuse to open the data. Let’s first write our dataset datacsv to a .csv file using the write_csv() function from the readr function. In the parentheses of write_csv(), we include the name of the dataset in R that we want to save (datacsv) and what we want the name of the dataset to be saved as (datacsv.csv).

We simply need to look in our working directory to see whether the file saved (in my case it saved successfully). Now let’s write datacsv to a .xlsx file using the write_xlsx() function from the writexl package; which we need to load first.
